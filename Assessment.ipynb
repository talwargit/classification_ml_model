{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e0d434",
   "metadata": {},
   "source": [
    "### **Project 2: Classification Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57ad05",
   "metadata": {},
   "source": [
    "One of the largest public sector banks which has several branches across cities provides various services like savings accounts, current accounts, term deposits, personal loans, home loans etc. to customers. Whenever the bank conducts marketing on its new schemes, it will keep track of data related to customers’ personal, social and economic details. Also, it maintains the detailing on efforts made to achieve success in the campaign. Recently, the bank has conducted a campaign to market their term-deposit scheme. Campaigns were conducted based mostly on direct phone calls, soliciting the bank's customers to place a term deposit. After all the marketing efforts, if the client had agreed to place a deposit, then the campaign is a success, otherwise not (Target variable marked 'yes', or 'no'). It is a challenge for bank officials to target the right people for a successful campaign. \n",
    "\n",
    "Tasks:\n",
    "1. Data loading, data cleaning and report analysis. (Weightage 30 Marks)\n",
    "2. Building ML-  Classification Model. (Weightage 70 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035d1a2",
   "metadata": {},
   "source": [
    "Data Dictionary:\n",
    "\n",
    "Age:\t(numeric)\n",
    "Job:\tType of job (categorical: 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed',\n",
    " \t'services', 'student', 'technician', 'unemployed', 'unknown')\n",
    "Marital :\tMarital status (categorical: 'divorced', 'married', 'single', 'unknown';Note: 'divorced' means divorced or widowed)\n",
    "Education:\t(categorical: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', \t'professional.course', 'university.degree', 'unknown')\n",
    "Default:\tHas credit in default? (categorical: 'no', 'yes', 'unknown')\n",
    "Housing:\tHas housing loan? (categorical: 'no', 'yes', 'unknown')\n",
    "Loan:\tHas personal loan? (categorical: 'no', 'yes', 'unknown')\n",
    "Contact:\tContact communication type (categorical: 'cellular', 'telephone')\n",
    "Month:\tLast contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "Day_of_week:\tlast contact day of the week (categorical: 'mon', 'tue', 'wed', 'thu', 'fri')\n",
    "Duration:\tLast contact duration, in seconds (numeric).\n",
    " \tImportant note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "Campaign:\tNumber of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "Pdays:\tNumber of days that passed by after the client was last contacted from a previous campaign: (numeric; 999 means client was not previously contacted)\n",
    "Previous:\tnumber of contacts performed before this campaign and for this client (numeric)\n",
    "Poutcome:\toutcome of the previous marketing campaign (categorical:\n",
    " \t'failure', 'nonexistent', 'success')\n",
    "Output variable (desired target):\n",
    "Y:\thas the client subscribed a term deposit? (binary: 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099b693",
   "metadata": {},
   "source": [
    "**Initial Guidelines:**\n",
    "\n",
    "1. Ensure to follow to Use Id’s provided by UNext for naming file as conventions.\n",
    "2. Create GitHub account and submit the GitHub link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdc4e0",
   "metadata": {},
   "source": [
    "### Software Engineering aspect:  \n",
    "\n",
    "Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c00c34",
   "metadata": {},
   "source": [
    "### General Instructions\n",
    "\n",
    "- The cells in the Jupyter notebook can be executed any number of times for testing the solution\n",
    "- Refrain from modifying the boilerplate code as it may lead to unexpected behavior\n",
    "- The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "- On completing all the questions, the assessment is to be submitted on moodle for evaluation\n",
    "- Before submitting the assessment, there should be `no error` while executing the notebook. If there are any error causing code, please comment it.\n",
    "- The kernel of the Jupyter notebook is to be set as `Python 3 (ipykernel)` if not set already\n",
    "- Include imports as necessary\n",
    "- For each of the task, `Note` section will provide you hints to solve the problem.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f6bf",
   "metadata": {},
   "source": [
    "#### **Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995c31a",
   "metadata": {},
   "source": [
    "### Loading required libraries and packages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b12073",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "Import various libraries and modules used in data analysis, machine learning, and visualization tasks in Python such as `pandas`, `numpy`, `sklearn`, `sklearn.preprocessing`,`seaborn`,`matplotlib`.There are 2 ways to import the libraries and modules:\n",
    "* import numpy as np\n",
    "* from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938faa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d228b",
   "metadata": {},
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights- (weightage - 15 marks) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0ed13",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "Loading the dataset for model building is the initial step in the machine learning pipeline, where the relevant data is imported into the chosen programming environment or framework. This process typically involves reading the dataset from a file (e.g., CSV, Excel, JSON) or fetching it from a database. Once loaded, the dataset is often inspected to understand its structure, including the number of samples, features, and target variables. Furthermore, preprocessing steps such as cleaning, handling missing values, encoding categorical variables, and scaling may be performed on the dataset to prepare it for model training. Loading the dataset accurately and efficiently is crucial for building accurate and robust machine learning models that effectively capture the underlying patterns and relationships within the data.\n",
    "\n",
    "- Do not use PRINT statement inside the Except Block. Please use `return` statement only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951503e",
   "metadata": {},
   "source": [
    "#### T1. Import following datasets      (Weightage- 3 marks)  (AE)\n",
    "-    customer_and_bankdetails\n",
    "-    customer_campaign_details\n",
    "-    customer_response_data\n",
    "-    customer_social_economic_data\n",
    "-    customer_postal_code_details\n",
    "-   state_master\n",
    "-    region_code_master\n",
    "-    city_master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b96af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_the_dataset_customer_and_bank_details():\n",
    "    customer_and_bankdetails = None\n",
    "    # Code starts here\n",
    "    customer_and_bankdetails = pd.read_csv(\"Datasets/Customer_and_bank_details.csv\")\n",
    "    # code ends here\n",
    "    return customer_and_bankdetails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa18a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  age          job  marital            education  default  \\\n",
      "0                1   56     services  married          high.school       no   \n",
      "1                2   45     services  married             basic.9y  unknown   \n",
      "2                3   59       admin.  married  professional.course       no   \n",
      "3                4   41  blue-collar  married              unknown  unknown   \n",
      "4                5   24   technician   single  professional.course       no   \n",
      "...            ...  ...          ...      ...                  ...      ...   \n",
      "37079        37080   73      retired  married  professional.course       no   \n",
      "37080        37081   46  blue-collar  married  professional.course       no   \n",
      "37081        37082   56      retired  married    university.degree       no   \n",
      "37082        37083   44   technician  married  professional.course       no   \n",
      "37083        37084   74      retired  married  professional.course       no   \n",
      "\n",
      "      housing loan Region_Code State_Code City_Code  \n",
      "0          no  yes           3         S1        C1  \n",
      "1          no   no           3         S1        C1  \n",
      "2          no   no           4         S2        C2  \n",
      "3          no   no           3         S3        C3  \n",
      "4         yes   no           3         S3        C3  \n",
      "...       ...  ...         ...        ...       ...  \n",
      "37079     yes   no           2        S16       C21  \n",
      "37080      no   no           2        S16       C21  \n",
      "37081     yes   no           2        S16       C21  \n",
      "37082      no   no           4        S17       C49  \n",
      "37083     yes   no           1         S6      C113  \n",
      "\n",
      "[37084 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#store the result of the dataset\n",
    "customer_and_bankdetails=load_the_dataset_customer_and_bank_details()\n",
    "\n",
    "print(customer_and_bankdetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_campaign_details\n",
    "\n",
    "def load_the_dataset_customer_campaign():\n",
    "    Customer_campaign_details = None\n",
    "    # Code starts here\n",
    "    Customer_campaign_details = pd.read_csv(\"Datasets/Customer_campaign_details.csv\")\n",
    "    # code ends here\n",
    "    return Customer_campaign_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fc6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id    contact month day_of_week  duration  campaign  pdays  \\\n",
      "0                1  telephone   may         mon       307         1    999   \n",
      "1                2  telephone   may         mon       198         1    999   \n",
      "2                3  telephone   may         mon       139         1    999   \n",
      "3                4  telephone   may         mon       217         1    999   \n",
      "4                5  telephone   may         mon       380         1    999   \n",
      "...            ...        ...   ...         ...       ...       ...    ...   \n",
      "37079        37080   cellular   nov         fri       334         1    999   \n",
      "37080        37081   cellular   nov         fri       383         1    999   \n",
      "37081        37082   cellular   nov         fri       189         2    999   \n",
      "37082        37083   cellular   nov         fri       442         1    999   \n",
      "37083        37084   cellular   nov         fri       239         3    999   \n",
      "\n",
      "       previous     poutcome  \n",
      "0             0  nonexistent  \n",
      "1             0  nonexistent  \n",
      "2             0  nonexistent  \n",
      "3             0  nonexistent  \n",
      "4             0  nonexistent  \n",
      "...         ...          ...  \n",
      "37079         0  nonexistent  \n",
      "37080         0  nonexistent  \n",
      "37081         0  nonexistent  \n",
      "37082         0  nonexistent  \n",
      "37083         1      failure  \n",
      "\n",
      "[37084 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_campaign_details=load_the_dataset_customer_campaign()\n",
    "print(Customer_campaign_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe1dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_Response_data\n",
    "\n",
    "def load_the_dataset_customer_response():\n",
    "    Customer_Response_data = None\n",
    "    # Code starts here\n",
    "    Customer_Response_data = pd.read_csv(\"Datasets/Customer_Response_data.csv\")\n",
    "    # code ends here\n",
    "    return Customer_Response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b04fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id    y\n",
      "0                1   no\n",
      "1                2   no\n",
      "2                3   no\n",
      "3                4   no\n",
      "4                5   no\n",
      "...            ...  ...\n",
      "37079        37080  yes\n",
      "37080        37081   no\n",
      "37081        37082   no\n",
      "37082        37083  yes\n",
      "37083        37084   no\n",
      "\n",
      "[37084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_Response_data=load_the_dataset_customer_response()\n",
    "print(Customer_Response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134dc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_social_economic_data\n",
    "\n",
    "def load_the_dataset_customer_social_economic_data():\n",
    "    Customer_social_economic_data = None\n",
    "    # Code starts here\n",
    "    Customer_social_economic_data = pd.read_csv(\"Datasets/Customer_social_economic_data.csv\")\n",
    "    # code ends here\n",
    "    return Customer_social_economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad5e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0                1           1.1          93.994          -36.4      4.857   \n",
      "1                2           1.1          93.994          -36.4      4.857   \n",
      "2                3           1.1          93.994          -36.4      4.857   \n",
      "3                4           1.1          93.994          -36.4      4.857   \n",
      "4                5           1.1          93.994          -36.4      4.857   \n",
      "...            ...           ...             ...            ...        ...   \n",
      "37079        37080          -1.1          94.767          -50.8      1.028   \n",
      "37080        37081          -1.1          94.767          -50.8      1.028   \n",
      "37081        37082          -1.1          94.767          -50.8      1.028   \n",
      "37082        37083          -1.1          94.767          -50.8      1.028   \n",
      "37083        37084          -1.1          94.767          -50.8      1.028   \n",
      "\n",
      "       nr.employed  \n",
      "0           5191.0  \n",
      "1           5191.0  \n",
      "2           5191.0  \n",
      "3           5191.0  \n",
      "4           5191.0  \n",
      "...            ...  \n",
      "37079       4963.6  \n",
      "37080       4963.6  \n",
      "37081       4963.6  \n",
      "37082       4963.6  \n",
      "37083       4963.6  \n",
      "\n",
      "[37084 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_social_economic_data=load_the_dataset_customer_social_economic_data()\n",
    "print(Customer_social_economic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9853a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import Customer_Postal_Code_details\n",
    "\n",
    "def load_the_dataset_customer_postal_code():\n",
    "    Customer_Postal_Code_details = None\n",
    "    # Code starts here\n",
    "    Customer_Postal_Code_details = pd.read_csv(\"Datasets/Customer_Postal_Code_details.csv\")\n",
    "    # code ends here\n",
    "    return Customer_Postal_Code_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c64fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       customer_id  Postal Code\n",
      "0                1        42420\n",
      "1                2        42420\n",
      "2                3        90036\n",
      "3                4        33311\n",
      "4                5        33311\n",
      "...            ...          ...\n",
      "37079        37080        10009\n",
      "37080        37081        10011\n",
      "37081        37082        10009\n",
      "37082        37083        85254\n",
      "37083        37084        79109\n",
      "\n",
      "[37084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_Postal_Code_details=load_the_dataset_customer_postal_code()\n",
    "print(Customer_Postal_Code_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d444f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import State_Master\n",
    "def load_the_dataset_state_master():\n",
    "    State_Master = None\n",
    "    # Code starts here\n",
    "    State_Master = pd.read_csv(\"Datasets/State_Master.csv\")\n",
    "    # code ends here\n",
    "    return State_Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a1dc89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   State_Code            State_Name  Region_Code\n",
      "0          S1              Kentucky            3\n",
      "1          S2            California            4\n",
      "2          S3               Florida            3\n",
      "3          S4        North Carolina            3\n",
      "4          S5            Washington            4\n",
      "5          S6                 Texas            1\n",
      "6          S7             Wisconsin            1\n",
      "7          S8                  Utah            4\n",
      "8          S9              Nebraska            1\n",
      "9         S10          Pennsylvania            2\n",
      "10        S11              Illinois            1\n",
      "11        S12             Minnesota            1\n",
      "12        S13              Michigan            1\n",
      "13        S14              Delaware            2\n",
      "14        S15               Indiana            1\n",
      "15        S16              New York            2\n",
      "16        S17               Arizona            4\n",
      "17        S18              Virginia            3\n",
      "18        S19             Tennessee            3\n",
      "19        S20               Alabama            3\n",
      "20        S21        South Carolina            3\n",
      "21        S22                Oregon            4\n",
      "22        S23              Colorado            4\n",
      "23        S24                  Iowa            1\n",
      "24        S25                  Ohio            2\n",
      "25        S26              Missouri            1\n",
      "26        S27              Oklahoma            1\n",
      "27        S28            New Mexico            4\n",
      "28        S29             Louisiana            3\n",
      "29        S30           Connecticut            2\n",
      "30        S31            New Jersey            2\n",
      "31        S32         Massachusetts            2\n",
      "32        S33               Georgia            3\n",
      "33        S34                Nevada            4\n",
      "34        S35          Rhode Island            2\n",
      "35        S36           Mississippi            3\n",
      "36        S37              Arkansas            3\n",
      "37        S38               Montana            4\n",
      "38        S39         New Hampshire            2\n",
      "39        S40              Maryland            2\n",
      "40        S41  District of Columbia            2\n",
      "41        S42                Kansas            1\n",
      "42        S43               Vermont            2\n",
      "43        S44                 Maine            2\n",
      "44        S45          South Dakota            1\n",
      "45        S46                 Idaho            4\n",
      "46        S47          North Dakota            1\n",
      "47        S48               Wyoming            4\n",
      "48        S49         West Virginia            2\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "State_Master=load_the_dataset_state_master()\n",
    "print(State_Master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcc0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import Region_code_master\n",
    "def load_the_dataset_region_code_master():\n",
    "    Region_code_master = None\n",
    "    # Code starts here\n",
    "    Region_code_master = pd.read_csv(\"Datasets/Region_code_master.csv\")\n",
    "    # code ends here\n",
    "    return Region_code_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca025344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region_Name  Region_Code\n",
      "0     Central            1\n",
      "1        East            2\n",
      "2       South            3\n",
      "3        West            4\n",
      "4       North            5\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Region_code_master=load_the_dataset_region_code_master()\n",
    "print(Region_code_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473bef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import City_Master\n",
    "def load_the_dataset_city_master():\n",
    "    City_Master = None\n",
    "    # Code starts here\n",
    "    City_Master = pd.read_csv(\"Datasets/City_Master.csv\")\n",
    "    # code ends here\n",
    "    return City_Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b478eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    City_Code        City_Name State_Code\n",
      "0          C1        Henderson         S1\n",
      "1          C2      Los Angeles         S2\n",
      "2          C3  Fort Lauderdale         S3\n",
      "3          C4          Concord         S4\n",
      "4          C5          Seattle         S5\n",
      "..        ...              ...        ...\n",
      "526      C527     San Clemente         S2\n",
      "527      C528  San Luis Obispo         S2\n",
      "528      C529       Springdale        S37\n",
      "529      C530             Lodi         S2\n",
      "530      C531            Mason        S25\n",
      "\n",
      "[531 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "City_Master=load_the_dataset_city_master()\n",
    "print(City_Master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f727d2",
   "metadata": {},
   "source": [
    "#### change column name of dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8595d65",
   "metadata": {},
   "source": [
    "* change the column_names in the Dataframe from 'customer_id'to 'Customer_id' wherever necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3433c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modname():\n",
    "    Custom = None\n",
    "    # Code starts here\n",
    "    Customer_Postal_Code_details.rename(columns={\"customer_id\":\"Customer_id\"},inplace=True)\n",
    "    # Code ends here\n",
    "    return Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abcebbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  Postal Code\n",
      "0                1        42420\n",
      "1                2        42420\n",
      "2                3        90036\n",
      "3                4        33311\n",
      "4                5        33311\n",
      "...            ...          ...\n",
      "37079        37080        10009\n",
      "37080        37081        10011\n",
      "37081        37082        10009\n",
      "37082        37083        85254\n",
      "37083        37084        79109\n",
      "\n",
      "[37084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Custom=modname()\n",
    "print(Customer_Postal_Code_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33889a3",
   "metadata": {},
   "source": [
    "#### T1.2. Create the updated dataframes by using relevant merging options and validate.  (Weightage-  8 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0c26d",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design the functions, custom_merge1(df1, df2),custom_merge2(df1, df2),custom_merge3(df1, df2),custom_merge4(df1, df2),custom_merge5(df1, df2),custom_merge6(df1, df2),custom_merge7(df1, df2) to merges two DataFrames (df1 and df2) based on a common column using an inner join.\n",
    "- Custom merge function\n",
    "- Hint: Inner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9a9fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_merge1(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on=\"Customer_id\", how=\"inner\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d0f218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  age          job  marital            education  default  \\\n",
      "0                1   56     services  married          high.school       no   \n",
      "1                2   45     services  married             basic.9y  unknown   \n",
      "2                3   59       admin.  married  professional.course       no   \n",
      "3                4   41  blue-collar  married              unknown  unknown   \n",
      "4                5   24   technician   single  professional.course       no   \n",
      "...            ...  ...          ...      ...                  ...      ...   \n",
      "37079        37080   73      retired  married  professional.course       no   \n",
      "37080        37081   46  blue-collar  married  professional.course       no   \n",
      "37081        37082   56      retired  married    university.degree       no   \n",
      "37082        37083   44   technician  married  professional.course       no   \n",
      "37083        37084   74      retired  married  professional.course       no   \n",
      "\n",
      "      housing loan Region_Code State_Code City_Code    contact month  \\\n",
      "0          no  yes           3         S1        C1  telephone   may   \n",
      "1          no   no           3         S1        C1  telephone   may   \n",
      "2          no   no           4         S2        C2  telephone   may   \n",
      "3          no   no           3         S3        C3  telephone   may   \n",
      "4         yes   no           3         S3        C3  telephone   may   \n",
      "...       ...  ...         ...        ...       ...        ...   ...   \n",
      "37079     yes   no           2        S16       C21   cellular   nov   \n",
      "37080      no   no           2        S16       C21   cellular   nov   \n",
      "37081     yes   no           2        S16       C21   cellular   nov   \n",
      "37082      no   no           4        S17       C49   cellular   nov   \n",
      "37083     yes   no           1         S6      C113   cellular   nov   \n",
      "\n",
      "      day_of_week  duration  campaign  pdays  previous     poutcome  \n",
      "0             mon       307         1    999         0  nonexistent  \n",
      "1             mon       198         1    999         0  nonexistent  \n",
      "2             mon       139         1    999         0  nonexistent  \n",
      "3             mon       217         1    999         0  nonexistent  \n",
      "4             mon       380         1    999         0  nonexistent  \n",
      "...           ...       ...       ...    ...       ...          ...  \n",
      "37079         fri       334         1    999         0  nonexistent  \n",
      "37080         fri       383         1    999         0  nonexistent  \n",
      "37081         fri       189         2    999         0  nonexistent  \n",
      "37082         fri       442         1    999         0  nonexistent  \n",
      "37083         fri       239         3    999         1      failure  \n",
      "\n",
      "[37084 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df = custom_merge1(customer_and_bankdetails,Customer_campaign_details)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed4be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Dataframe: df2=df1 and customer_response_data\n",
    "# Hint: Inner\n",
    "# Validate rows and columns numbers = [37084 rows x 20 columns]\n",
    "def custom_merge2(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df2, df1, on=\"Customer_id\", how=\"inner\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1505ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id    y  age          job  marital            education  \\\n",
      "0                1   no   56     services  married          high.school   \n",
      "1                2   no   45     services  married             basic.9y   \n",
      "2                3   no   59       admin.  married  professional.course   \n",
      "3                4   no   41  blue-collar  married              unknown   \n",
      "4                5   no   24   technician   single  professional.course   \n",
      "...            ...  ...  ...          ...      ...                  ...   \n",
      "37079        37080  yes   73      retired  married  professional.course   \n",
      "37080        37081   no   46  blue-collar  married  professional.course   \n",
      "37081        37082   no   56      retired  married    university.degree   \n",
      "37082        37083  yes   44   technician  married  professional.course   \n",
      "37083        37084   no   74      retired  married  professional.course   \n",
      "\n",
      "       default housing loan Region_Code State_Code City_Code    contact month  \\\n",
      "0           no      no  yes           3         S1        C1  telephone   may   \n",
      "1      unknown      no   no           3         S1        C1  telephone   may   \n",
      "2           no      no   no           4         S2        C2  telephone   may   \n",
      "3      unknown      no   no           3         S3        C3  telephone   may   \n",
      "4           no     yes   no           3         S3        C3  telephone   may   \n",
      "...        ...     ...  ...         ...        ...       ...        ...   ...   \n",
      "37079       no     yes   no           2        S16       C21   cellular   nov   \n",
      "37080       no      no   no           2        S16       C21   cellular   nov   \n",
      "37081       no     yes   no           2        S16       C21   cellular   nov   \n",
      "37082       no      no   no           4        S17       C49   cellular   nov   \n",
      "37083       no     yes   no           1         S6      C113   cellular   nov   \n",
      "\n",
      "      day_of_week  duration  campaign  pdays  previous     poutcome  \n",
      "0             mon       307         1    999         0  nonexistent  \n",
      "1             mon       198         1    999         0  nonexistent  \n",
      "2             mon       139         1    999         0  nonexistent  \n",
      "3             mon       217         1    999         0  nonexistent  \n",
      "4             mon       380         1    999         0  nonexistent  \n",
      "...           ...       ...       ...    ...       ...          ...  \n",
      "37079         fri       334         1    999         0  nonexistent  \n",
      "37080         fri       383         1    999         0  nonexistent  \n",
      "37081         fri       189         2    999         0  nonexistent  \n",
      "37082         fri       442         1    999         0  nonexistent  \n",
      "37083         fri       239         3    999         1      failure  \n",
      "\n",
      "[37084 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df1 = custom_merge2(result_df,Customer_Response_data)\n",
    "print(result_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df782cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Dataframe: df3=df2 and customer_social_economic_data\n",
    "# Validate rows and columns numbers = [37084 rows x 25 columns]\n",
    "# Hint: Inner\n",
    "def custom_merge3(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on=\"Customer_id\", how=\"inner\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3b94c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id    y  age          job  marital            education  \\\n",
      "0                1   no   56     services  married          high.school   \n",
      "1                2   no   45     services  married             basic.9y   \n",
      "2                3   no   59       admin.  married  professional.course   \n",
      "3                4   no   41  blue-collar  married              unknown   \n",
      "4                5   no   24   technician   single  professional.course   \n",
      "...            ...  ...  ...          ...      ...                  ...   \n",
      "37079        37080  yes   73      retired  married  professional.course   \n",
      "37080        37081   no   46  blue-collar  married  professional.course   \n",
      "37081        37082   no   56      retired  married    university.degree   \n",
      "37082        37083  yes   44   technician  married  professional.course   \n",
      "37083        37084   no   74      retired  married  professional.course   \n",
      "\n",
      "       default housing loan Region_Code  ... duration campaign pdays previous  \\\n",
      "0           no      no  yes           3  ...      307        1   999        0   \n",
      "1      unknown      no   no           3  ...      198        1   999        0   \n",
      "2           no      no   no           4  ...      139        1   999        0   \n",
      "3      unknown      no   no           3  ...      217        1   999        0   \n",
      "4           no     yes   no           3  ...      380        1   999        0   \n",
      "...        ...     ...  ...         ...  ...      ...      ...   ...      ...   \n",
      "37079       no     yes   no           2  ...      334        1   999        0   \n",
      "37080       no      no   no           2  ...      383        1   999        0   \n",
      "37081       no     yes   no           2  ...      189        2   999        0   \n",
      "37082       no      no   no           4  ...      442        1   999        0   \n",
      "37083       no     yes   no           1  ...      239        3   999        1   \n",
      "\n",
      "          poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0      nonexistent           1.1          93.994          -36.4      4.857   \n",
      "1      nonexistent           1.1          93.994          -36.4      4.857   \n",
      "2      nonexistent           1.1          93.994          -36.4      4.857   \n",
      "3      nonexistent           1.1          93.994          -36.4      4.857   \n",
      "4      nonexistent           1.1          93.994          -36.4      4.857   \n",
      "...            ...           ...             ...            ...        ...   \n",
      "37079  nonexistent          -1.1          94.767          -50.8      1.028   \n",
      "37080  nonexistent          -1.1          94.767          -50.8      1.028   \n",
      "37081  nonexistent          -1.1          94.767          -50.8      1.028   \n",
      "37082  nonexistent          -1.1          94.767          -50.8      1.028   \n",
      "37083      failure          -1.1          94.767          -50.8      1.028   \n",
      "\n",
      "      nr.employed  \n",
      "0          5191.0  \n",
      "1          5191.0  \n",
      "2          5191.0  \n",
      "3          5191.0  \n",
      "4          5191.0  \n",
      "...           ...  \n",
      "37079      4963.6  \n",
      "37080      4963.6  \n",
      "37081      4963.6  \n",
      "37082      4963.6  \n",
      "37083      4963.6  \n",
      "\n",
      "[37084 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df2 = custom_merge3(result_df1,Customer_social_economic_data)\n",
    "print(result_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "214fa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth Dataframe: df4= df3 and customer_postal_code_details\n",
    "#Validate rows and columns numbers = [37084 rows x 26 columns]\n",
    "#Hint: Inner\n",
    "\n",
    "def custom_merge4(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on = \"Customer_id\", how = \"inner\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "764bda12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id    y  age          job  marital            education  \\\n",
      "0                1   no   56     services  married          high.school   \n",
      "1                2   no   45     services  married             basic.9y   \n",
      "2                3   no   59       admin.  married  professional.course   \n",
      "3                4   no   41  blue-collar  married              unknown   \n",
      "4                5   no   24   technician   single  professional.course   \n",
      "...            ...  ...  ...          ...      ...                  ...   \n",
      "37079        37080  yes   73      retired  married  professional.course   \n",
      "37080        37081   no   46  blue-collar  married  professional.course   \n",
      "37081        37082   no   56      retired  married    university.degree   \n",
      "37082        37083  yes   44   technician  married  professional.course   \n",
      "37083        37084   no   74      retired  married  professional.course   \n",
      "\n",
      "       default housing loan Region_Code  ... campaign pdays previous  \\\n",
      "0           no      no  yes           3  ...        1   999        0   \n",
      "1      unknown      no   no           3  ...        1   999        0   \n",
      "2           no      no   no           4  ...        1   999        0   \n",
      "3      unknown      no   no           3  ...        1   999        0   \n",
      "4           no     yes   no           3  ...        1   999        0   \n",
      "...        ...     ...  ...         ...  ...      ...   ...      ...   \n",
      "37079       no     yes   no           2  ...        1   999        0   \n",
      "37080       no      no   no           2  ...        1   999        0   \n",
      "37081       no     yes   no           2  ...        2   999        0   \n",
      "37082       no      no   no           4  ...        1   999        0   \n",
      "37083       no     yes   no           1  ...        3   999        1   \n",
      "\n",
      "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "...            ...          ...             ...            ...        ...   \n",
      "37079  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "37080  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "37081  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "37082  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "37083      failure         -1.1          94.767          -50.8      1.028   \n",
      "\n",
      "       nr.employed Postal Code  \n",
      "0           5191.0       42420  \n",
      "1           5191.0       42420  \n",
      "2           5191.0       90036  \n",
      "3           5191.0       33311  \n",
      "4           5191.0       33311  \n",
      "...            ...         ...  \n",
      "37079       4963.6       10009  \n",
      "37080       4963.6       10011  \n",
      "37081       4963.6       10009  \n",
      "37082       4963.6       85254  \n",
      "37083       4963.6       79109  \n",
      "\n",
      "[37084 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df3 = custom_merge4(result_df2,Customer_Postal_Code_details)\n",
    "print(result_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6617d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fifth Dataframe: df5= state_master and region_code_master\n",
    "#Validate rows and columns numbers = 49 rows and 4 columns\n",
    "#Hint: Left\n",
    "def custom_merge5(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on = \"Region_Code\", how = \"left\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "849c488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   State_Code            State_Name  Region_Code Region_Name\n",
      "0          S1              Kentucky            3       South\n",
      "1          S2            California            4        West\n",
      "2          S3               Florida            3       South\n",
      "3          S4        North Carolina            3       South\n",
      "4          S5            Washington            4        West\n",
      "5          S6                 Texas            1     Central\n",
      "6          S7             Wisconsin            1     Central\n",
      "7          S8                  Utah            4        West\n",
      "8          S9              Nebraska            1     Central\n",
      "9         S10          Pennsylvania            2        East\n",
      "10        S11              Illinois            1     Central\n",
      "11        S12             Minnesota            1     Central\n",
      "12        S13              Michigan            1     Central\n",
      "13        S14              Delaware            2        East\n",
      "14        S15               Indiana            1     Central\n",
      "15        S16              New York            2        East\n",
      "16        S17               Arizona            4        West\n",
      "17        S18              Virginia            3       South\n",
      "18        S19             Tennessee            3       South\n",
      "19        S20               Alabama            3       South\n",
      "20        S21        South Carolina            3       South\n",
      "21        S22                Oregon            4        West\n",
      "22        S23              Colorado            4        West\n",
      "23        S24                  Iowa            1     Central\n",
      "24        S25                  Ohio            2        East\n",
      "25        S26              Missouri            1     Central\n",
      "26        S27              Oklahoma            1     Central\n",
      "27        S28            New Mexico            4        West\n",
      "28        S29             Louisiana            3       South\n",
      "29        S30           Connecticut            2        East\n",
      "30        S31            New Jersey            2        East\n",
      "31        S32         Massachusetts            2        East\n",
      "32        S33               Georgia            3       South\n",
      "33        S34                Nevada            4        West\n",
      "34        S35          Rhode Island            2        East\n",
      "35        S36           Mississippi            3       South\n",
      "36        S37              Arkansas            3       South\n",
      "37        S38               Montana            4        West\n",
      "38        S39         New Hampshire            2        East\n",
      "39        S40              Maryland            2        East\n",
      "40        S41  District of Columbia            2        East\n",
      "41        S42                Kansas            1     Central\n",
      "42        S43               Vermont            2        East\n",
      "43        S44                 Maine            2        East\n",
      "44        S45          South Dakota            1     Central\n",
      "45        S46                 Idaho            4        West\n",
      "46        S47          North Dakota            1     Central\n",
      "47        S48               Wyoming            4        West\n",
      "48        S49         West Virginia            2        East\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df4 = custom_merge5(State_Master,Region_code_master)\n",
    "print(result_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d48148b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_merge6(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on = \"State_Code\", how = \"left\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eee39c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    City_Code        City_Name State_Code      State_Name  Region_Code  \\\n",
      "0          C1        Henderson         S1        Kentucky            3   \n",
      "1          C2      Los Angeles         S2      California            4   \n",
      "2          C3  Fort Lauderdale         S3         Florida            3   \n",
      "3          C4          Concord         S4  North Carolina            3   \n",
      "4          C5          Seattle         S5      Washington            4   \n",
      "..        ...              ...        ...             ...          ...   \n",
      "526      C527     San Clemente         S2      California            4   \n",
      "527      C528  San Luis Obispo         S2      California            4   \n",
      "528      C529       Springdale        S37        Arkansas            3   \n",
      "529      C530             Lodi         S2      California            4   \n",
      "530      C531            Mason        S25            Ohio            2   \n",
      "\n",
      "    Region_Name  \n",
      "0         South  \n",
      "1          West  \n",
      "2         South  \n",
      "3         South  \n",
      "4          West  \n",
      "..          ...  \n",
      "526        West  \n",
      "527        West  \n",
      "528       South  \n",
      "529        West  \n",
      "530        East  \n",
      "\n",
      "[531 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df5 = custom_merge6(City_Master,result_df4)\n",
    "print(result_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "906abbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_merge7(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df = pd.merge(df1, df2, on = \"City_Code\", how = \"inner\")\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e791cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id   y  age          job   marital          education  \\\n",
      "0                1  no   56     services   married        high.school   \n",
      "1                2  no   45     services   married           basic.9y   \n",
      "2              539  no   32       admin.    single  university.degree   \n",
      "3              540  no   36     services   married        high.school   \n",
      "4              997  no   31  blue-collar   married           basic.9y   \n",
      "...            ...  ..  ...          ...       ...                ...   \n",
      "37079        19864  no   47       admin.  divorced  university.degree   \n",
      "37080        19865  no   58      retired   married           basic.4y   \n",
      "37081        29857  no   35       admin.   married        high.school   \n",
      "37082        29858  no   38   technician   married        high.school   \n",
      "37083        29859  no   50      unknown   married           basic.4y   \n",
      "\n",
      "       default housing loan Region_Code_x  ... cons.price.idx cons.conf.idx  \\\n",
      "0           no      no  yes             3  ...         93.994         -36.4   \n",
      "1      unknown      no   no             3  ...         93.994         -36.4   \n",
      "2           no      no   no             3  ...         93.994         -36.4   \n",
      "3           no      no   no             3  ...         93.994         -36.4   \n",
      "4           no      no   no             3  ...         93.994         -36.4   \n",
      "...        ...     ...  ...           ...  ...            ...           ...   \n",
      "37079       no      no   no             2  ...         93.444         -36.1   \n",
      "37080       no     yes   no             2  ...         93.444         -36.1   \n",
      "37081       no     yes   no             2  ...         92.893         -46.2   \n",
      "37082       no     yes   no             2  ...         92.893         -46.2   \n",
      "37083  unknown     yes   no             2  ...         92.893         -46.2   \n",
      "\n",
      "      euribor3m nr.employed Postal Code  City_Name  State_Code_y  State_Name  \\\n",
      "0         4.857      5191.0       42420  Henderson            S1    Kentucky   \n",
      "1         4.857      5191.0       42420  Henderson            S1    Kentucky   \n",
      "2         4.857      5191.0       42420  Henderson            S1    Kentucky   \n",
      "3         4.857      5191.0       42420  Henderson            S1    Kentucky   \n",
      "4         4.856      5191.0       42420  Henderson            S1    Kentucky   \n",
      "...         ...         ...         ...        ...           ...         ...   \n",
      "37079     4.964      5228.1       45040      Mason           S25        Ohio   \n",
      "37080     4.964      5228.1       45040      Mason           S25        Ohio   \n",
      "37081     1.291      5099.1       45040      Mason           S25        Ohio   \n",
      "37082     1.291      5099.1       45040      Mason           S25        Ohio   \n",
      "37083     1.291      5099.1       45040      Mason           S25        Ohio   \n",
      "\n",
      "       Region_Code_y Region_Name  \n",
      "0                  3       South  \n",
      "1                  3       South  \n",
      "2                  3       South  \n",
      "3                  3       South  \n",
      "4                  3       South  \n",
      "...              ...         ...  \n",
      "37079              2        East  \n",
      "37080              2        East  \n",
      "37081              2        East  \n",
      "37082              2        East  \n",
      "37083              2        East  \n",
      "\n",
      "[37084 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "df = custom_merge7(result_df3,result_df5)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c606aa",
   "metadata": {},
   "source": [
    "#### Refer to the Github document from Lumen to create the repository and steps to commit \n",
    "\n",
    "#### Add your Github repository link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9035638e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2288599001.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[34], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://github.com/talwargit/classification_ml_model\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://github.com/talwargit/classification_ml_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce7139",
   "metadata": {},
   "source": [
    "#### T1.3. Export the final data frame df to GitHub for versioning.  (Weightage-2 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0fef4",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Design a function `export_to_csv` export the DataFrame to a CSV file with the specified filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52bc13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(df, filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Exports a Pandas DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to export.\n",
    "        filename (str): The desired filename for the CSV file.\n",
    "    \"\"\"\n",
    "# Code starts here\n",
    "    df.to_csv(filename, index = False)\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2502482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "my_dataframe = pd.DataFrame(df)  # Your actual DataFrame here\n",
    "export_to_csv(my_dataframe, \"my_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5475b7",
   "metadata": {},
   "source": [
    "#### T1.4. Reporting (Weightage- 2 marks each)  (ME)\n",
    "1.\tCustomer contact mode made.\n",
    "2.\tAnalysis on attempts made to turn a person into successful depositor.\n",
    "3.\tData analysis on marital status, existing loans, education, profession etc. and its impact on the campaign’s success\n",
    "4.\tSocio-economic analysis of the customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cef19d",
   "metadata": {},
   "source": [
    "### Task 2: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights- (weightage - 35 marks) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b27add",
   "metadata": {},
   "source": [
    "#### T2.1 Import the data stored above from GITHUB using try and except blocks for modelling and create data frame “df” (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1b7ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_the_dataset_from_github():\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "    try:\n",
    "        url = \"https://github.com/talwargit/classification_ml_model/raw/main/my_data.csv\"\n",
    "        df = pd.read_csv(url)\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "    except:\n",
    "        df = None\n",
    "    # Code ends here  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d12c9f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3687/633741066.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "df=load_the_dataset_from_github()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bea5d",
   "metadata": {},
   "source": [
    "#### T2.2\tDrop the columns from the data frame df: 'Customer_id', 'Region_Code_y','Region_Code_x', 'State_Code_x',  \"City_Code\", ' State_Code_y',  'Postal Code', 'City_Name', 'State_Code_y', 'State_Name', 'Region_Code_y', 'Region_Name' . (weightage 2 marks) AE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bd3e2",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `drop_var` to drop/remove specific columns from the Data frame\n",
    "- Dropping columns from a DataFrame involves removing specific columns that are not required for analysis or modeling.\n",
    "- This operation helps streamline the dataset and focus on relevant variables, reducing complexity and improving computational efficiency.\n",
    "- Before dropping columns, it's essential to identify the columns to be removed based on their names or indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a36ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the given variables\n",
    "def drop_var(df):\n",
    "    x = None\n",
    "    # Code starts here\n",
    "    x = df.drop([ 'Customer_id', 'Region_Code_y','Region_Code_x', 'State_Code_x', 'City_Code', 'State_Code_y', 'Postal Code', 'City_Name', 'State_Code_y', 'State_Name', 'Region_Code_y', 'Region_Name'],axis=1)\n",
    "    # Code ends here\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d48055a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y  age          job   marital          education  default housing  \\\n",
      "0      no   56     services   married        high.school       no      no   \n",
      "1      no   45     services   married           basic.9y  unknown      no   \n",
      "2      no   32       admin.    single  university.degree       no      no   \n",
      "3      no   36     services   married        high.school       no      no   \n",
      "4      no   31  blue-collar   married           basic.9y       no      no   \n",
      "...    ..  ...          ...       ...                ...      ...     ...   \n",
      "37079  no   47       admin.  divorced  university.degree       no      no   \n",
      "37080  no   58      retired   married           basic.4y       no     yes   \n",
      "37081  no   35       admin.   married        high.school       no     yes   \n",
      "37082  no   38   technician   married        high.school       no     yes   \n",
      "37083  no   50      unknown   married           basic.4y  unknown     yes   \n",
      "\n",
      "      loan    contact month  ... duration  campaign  pdays  previous  \\\n",
      "0      yes  telephone   may  ...      307         1    999         0   \n",
      "1       no  telephone   may  ...      198         1    999         0   \n",
      "2       no  telephone   may  ...      389         1    999         0   \n",
      "3       no  telephone   may  ...      158         1    999         0   \n",
      "4       no  telephone   may  ...      196         2    999         0   \n",
      "...    ...        ...   ...  ...      ...       ...    ...       ...   \n",
      "37079   no   cellular   aug  ...      381         3    999         0   \n",
      "37080   no   cellular   aug  ...       83         3    999         0   \n",
      "37081   no   cellular   may  ...       12         6    999         1   \n",
      "37082   no   cellular   may  ...      114         6    999         0   \n",
      "37083   no   cellular   may  ...       12         8    999         0   \n",
      "\n",
      "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "4      nonexistent          1.1          93.994          -36.4      4.856   \n",
      "...            ...          ...             ...            ...        ...   \n",
      "37079  nonexistent          1.4          93.444          -36.1      4.964   \n",
      "37080  nonexistent          1.4          93.444          -36.1      4.964   \n",
      "37081      failure         -1.8          92.893          -46.2      1.291   \n",
      "37082  nonexistent         -1.8          92.893          -46.2      1.291   \n",
      "37083  nonexistent         -1.8          92.893          -46.2      1.291   \n",
      "\n",
      "       nr.employed  \n",
      "0           5191.0  \n",
      "1           5191.0  \n",
      "2           5191.0  \n",
      "3           5191.0  \n",
      "4           5191.0  \n",
      "...            ...  \n",
      "37079       5228.1  \n",
      "37080       5228.1  \n",
      "37081       5099.1  \n",
      "37082       5099.1  \n",
      "37083       5099.1  \n",
      "\n",
      "[37084 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df=drop_var(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3335b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   y               37084 non-null  object \n",
      " 1   age             37084 non-null  int64  \n",
      " 2   job             37084 non-null  object \n",
      " 3   marital         37084 non-null  object \n",
      " 4   education       37084 non-null  object \n",
      " 5   default         37084 non-null  object \n",
      " 6   housing         37084 non-null  object \n",
      " 7   loan            37084 non-null  object \n",
      " 8   contact         37084 non-null  object \n",
      " 9   month           37084 non-null  object \n",
      " 10  day_of_week     37084 non-null  object \n",
      " 11  duration        37084 non-null  int64  \n",
      " 12  campaign        37084 non-null  int64  \n",
      " 13  pdays           37084 non-null  int64  \n",
      " 14  previous        37084 non-null  int64  \n",
      " 15  poutcome        37084 non-null  object \n",
      " 16  emp.var.rate    37084 non-null  float64\n",
      " 17  cons.price.idx  37084 non-null  float64\n",
      " 18  cons.conf.idx   37084 non-null  float64\n",
      " 19  euribor3m       37084 non-null  float64\n",
      " 20  nr.employed     37084 non-null  float64\n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b89e14",
   "metadata": {},
   "source": [
    "#### T2.3\tChange the order of columns as per data dictionary. (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc3a32",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `reorder` to rearrange specific columns from the Data frame.\n",
    "- A data dictionary provides metadata about the variables or attributes in a dataset, including their names, descriptions, data types, and order.\n",
    "- It serves as a reference guide for understanding the structure and meaning of the data.\n",
    "- Changing the order of columns in a DataFrame involves rearranging the columns to match the specified order in the data dictionary.\n",
    "- This ensures consistency between the dataset's structure and the documented metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93adc49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   y               37084 non-null  object \n",
      " 1   age             37084 non-null  int64  \n",
      " 2   job             37084 non-null  object \n",
      " 3   marital         37084 non-null  object \n",
      " 4   education       37084 non-null  object \n",
      " 5   default         37084 non-null  object \n",
      " 6   housing         37084 non-null  object \n",
      " 7   loan            37084 non-null  object \n",
      " 8   contact         37084 non-null  object \n",
      " 9   month           37084 non-null  object \n",
      " 10  day_of_week     37084 non-null  object \n",
      " 11  duration        37084 non-null  int64  \n",
      " 12  campaign        37084 non-null  int64  \n",
      " 13  pdays           37084 non-null  int64  \n",
      " 14  previous        37084 non-null  int64  \n",
      " 15  poutcome        37084 non-null  object \n",
      " 16  emp.var.rate    37084 non-null  float64\n",
      " 17  cons.price.idx  37084 non-null  float64\n",
      " 18  cons.conf.idx   37084 non-null  float64\n",
      " 19  euribor3m       37084 non-null  float64\n",
      " 20  nr.employed     37084 non-null  float64\n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "23956d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df):\n",
    "   \n",
    "   x = None\n",
    "   # Code starts here\n",
    "   x = df\n",
    "   # Code ends here\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69024980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y  age          job   marital          education  default housing  \\\n",
      "0      no   56     services   married        high.school       no      no   \n",
      "1      no   45     services   married           basic.9y  unknown      no   \n",
      "2      no   32       admin.    single  university.degree       no      no   \n",
      "3      no   36     services   married        high.school       no      no   \n",
      "4      no   31  blue-collar   married           basic.9y       no      no   \n",
      "...    ..  ...          ...       ...                ...      ...     ...   \n",
      "37079  no   47       admin.  divorced  university.degree       no      no   \n",
      "37080  no   58      retired   married           basic.4y       no     yes   \n",
      "37081  no   35       admin.   married        high.school       no     yes   \n",
      "37082  no   38   technician   married        high.school       no     yes   \n",
      "37083  no   50      unknown   married           basic.4y  unknown     yes   \n",
      "\n",
      "      loan    contact month  ... duration  campaign  pdays  previous  \\\n",
      "0      yes  telephone   may  ...      307         1    999         0   \n",
      "1       no  telephone   may  ...      198         1    999         0   \n",
      "2       no  telephone   may  ...      389         1    999         0   \n",
      "3       no  telephone   may  ...      158         1    999         0   \n",
      "4       no  telephone   may  ...      196         2    999         0   \n",
      "...    ...        ...   ...  ...      ...       ...    ...       ...   \n",
      "37079   no   cellular   aug  ...      381         3    999         0   \n",
      "37080   no   cellular   aug  ...       83         3    999         0   \n",
      "37081   no   cellular   may  ...       12         6    999         1   \n",
      "37082   no   cellular   may  ...      114         6    999         0   \n",
      "37083   no   cellular   may  ...       12         8    999         0   \n",
      "\n",
      "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "4      nonexistent          1.1          93.994          -36.4      4.856   \n",
      "...            ...          ...             ...            ...        ...   \n",
      "37079  nonexistent          1.4          93.444          -36.1      4.964   \n",
      "37080  nonexistent          1.4          93.444          -36.1      4.964   \n",
      "37081      failure         -1.8          92.893          -46.2      1.291   \n",
      "37082  nonexistent         -1.8          92.893          -46.2      1.291   \n",
      "37083  nonexistent         -1.8          92.893          -46.2      1.291   \n",
      "\n",
      "       nr.employed  \n",
      "0           5191.0  \n",
      "1           5191.0  \n",
      "2           5191.0  \n",
      "3           5191.0  \n",
      "4           5191.0  \n",
      "...            ...  \n",
      "37079       5228.1  \n",
      "37080       5228.1  \n",
      "37081       5099.1  \n",
      "37082       5099.1  \n",
      "37083       5099.1  \n",
      "\n",
      "[37084 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=reorder(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848de9ca",
   "metadata": {},
   "source": [
    "#### T2.4\tGet the counts of values for the attribute target variable – ‘y’ (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be7d5a",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `get_y_counts` to get the counts of the most common values from the Data frame\n",
    "- The target variable, often denoted as 'y', is the variable of interest in a predictive modeling task.\n",
    "- It represents the outcome or response variable that the model aims to predict based on the input features.\n",
    "- Getting the counts of values for the target variable provides insights into the distribution of outcomes or classes.\n",
    "- It helps in understanding the balance or imbalance between different classes and assessing the prevalence of each class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3850822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get count of values for the variable y\n",
    "\n",
    "def get_y_counts(df):\n",
    "    y_value_counts = None\n",
    "    # Code starts here\n",
    "    y_value_counts = df['y'].value_counts()\n",
    "    # Code ends here\n",
    "    return y_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92e2c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     32876\n",
      "yes     4208\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1=get_y_counts(df)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a8bdf",
   "metadata": {},
   "source": [
    "#### T2.5 Check missing values in the data in terms of percentage using error handling technique  and do missing value treatment. (weightage 2 marks) AE  \n",
    "\n",
    "\n",
    "#### NOTE:\n",
    "-  Get sum/ percentage of null values to find any missing values if present in data or not, for all the attributes in data frame ‘df’ \n",
    "- Missing values are data points that are absent or unavailable in the dataset, often represented as NaN (Not a Number) or null values.\n",
    "- Detecting missing values is a critical step in data preprocessing to ensure data integrity and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b30dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_check(data):\n",
    "    missing_percentage = None\n",
    "    # Code starts here\n",
    "    missing_percentage = df.isnull().mean() * 100\n",
    "    # Code ends here\n",
    "    return  missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "73c0a1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y                 0.0\n",
       "age               0.0\n",
       "job               0.0\n",
       "marital           0.0\n",
       "education         0.0\n",
       "default           0.0\n",
       "housing           0.0\n",
       "loan              0.0\n",
       "contact           0.0\n",
       "month             0.0\n",
       "day_of_week       0.0\n",
       "duration          0.0\n",
       "campaign          0.0\n",
       "pdays             0.0\n",
       "previous          0.0\n",
       "poutcome          0.0\n",
       "emp.var.rate      0.0\n",
       "cons.price.idx    0.0\n",
       "cons.conf.idx     0.0\n",
       "euribor3m         0.0\n",
       "nr.employed       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_check(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ff774",
   "metadata": {},
   "source": [
    "df2=get_all_sum()\n",
    "print(df2)\n",
    "\n",
    "#df.info()\n",
    "#df.head()\n",
    "\n",
    "#df.isnull().sum()\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f664bc7",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `rows_columns` to get the number of rows and columns from the Data frame.\n",
    "- The total number of rows and columns in a dataset provides information about its dimensionality.\n",
    "- The number of rows represents the observations or samples in the dataset, while the number of columns represents the variables or features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bca41",
   "metadata": {},
   "source": [
    "#### T2.6 Check total number of rows and columns in the dataset (Weightage 2 marks )AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc7be1",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `rows_columns` to get the number of rows and columns from the Data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a16f8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_columns(df): \n",
    "    x = None\n",
    "    # Code starts here\n",
    "    x = df.shape\n",
    "    # Code ends here\n",
    "    return(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "34a2984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37084, 21)\n"
     ]
    }
   ],
   "source": [
    "RowsCols=rows_columns(df) \n",
    "print(RowsCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ef275",
   "metadata": {},
   "source": [
    "#### T2.7 Get the descriptive statistics for all the columns in the data frame. (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE:\n",
    "- Descriptive statistics provide a summary of the key characteristics or properties of the data, helping to understand its distribution, central tendency, dispersion, and shape.\n",
    "- Common descriptive statistics include measures of central tendency (mean, median, mode), measures of dispersion (standard deviation, variance, range), and measures of shape (skewness, kurtosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2e5621c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "      <td>37084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.042714</td>\n",
       "      <td>258.237946</td>\n",
       "      <td>2.569545</td>\n",
       "      <td>962.530849</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.082669</td>\n",
       "      <td>93.576076</td>\n",
       "      <td>-40.505183</td>\n",
       "      <td>3.621668</td>\n",
       "      <td>5167.058664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.432965</td>\n",
       "      <td>258.730909</td>\n",
       "      <td>2.770611</td>\n",
       "      <td>186.773063</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>1.568997</td>\n",
       "      <td>0.578493</td>\n",
       "      <td>4.622045</td>\n",
       "      <td>1.733972</td>\n",
       "      <td>72.196605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>319.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      duration      campaign         pdays      previous  \\\n",
       "count  37084.000000  37084.000000  37084.000000  37084.000000  37084.000000   \n",
       "mean      40.042714    258.237946      2.569545    962.530849      0.172986   \n",
       "std       10.432965    258.730909      2.770611    186.773063      0.495681   \n",
       "min       17.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       32.000000    102.000000      1.000000    999.000000      0.000000   \n",
       "50%       38.000000    180.000000      2.000000    999.000000      0.000000   \n",
       "75%       47.000000    319.250000      3.000000    999.000000      0.000000   \n",
       "max       98.000000   4918.000000     56.000000    999.000000      7.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count  37084.000000    37084.000000   37084.000000  37084.000000  37084.000000  \n",
       "mean       0.082669       93.576076     -40.505183      3.621668   5167.058664  \n",
       "std        1.568997        0.578493       4.622045      1.733972     72.196605  \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
       "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
       "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to get descriptive statistics for all numeric columns using describe function\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed8018",
   "metadata": {},
   "source": [
    "#### T2.8\tChange pday values if the value is 999 replace with ‘no’ else ‘yes’ (Weightage 2 marks )AE\n",
    "\n",
    "- changing pdays()values \n",
    "\n",
    "#### NOTE:\n",
    "- Design a Function `pcontacted` to replace pdays values if the value is '999' replace it with 'no' else replace it with a 'yes'\n",
    "- Changing the values in the 'pday' column involves transforming the existing numerical values to categorical labels based on a specified condition.\n",
    "- This transformation allows for a more intuitive interpretation of the data and facilitates subsequent analysis or visualization tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b5decddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcontacted(x):\n",
    "    # Code starts here\n",
    "    if x == 999:\n",
    "        return \"no\"\n",
    "    else:\n",
    "        return \"yes\"\n",
    "    # Code ends here\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "515b1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pdays'] = df['pdays'].apply(pcontacted)\n",
    "# print(df['pdays'])\n",
    "# print(pcontacted(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b2025",
   "metadata": {},
   "source": [
    "#### T2.9 Rename ‘pdays’ column name with ‘bcontacted’ and get value counts and find number of ‘yes’ and ‘no’. Perform binomial test for proportions on pdays and give inferences based on pvalues (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE: \n",
    "\n",
    "- Renaming the 'pdays' column to 'bcontacted' involves changing the name of the column to better reflect its meaning or purpose in the dataset.\n",
    "- `'bcontacted'` suggests that the column represents whether a contact has been made (binary indicator), which may be more intuitive than 'pdays' (number of days since the client was last contacted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a37b7785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     35722\n",
       "yes     1362\n",
       "Name: bcontacted, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'pdays':'bcontacted'}, inplace=True)\n",
    "df['bcontacted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9377f",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Design a Function to determine whether the proportion of successes in a binary outcome variable ('pdays') is significantly different from a specified null hypothesis proportion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom_test\n",
    "p_value = None\n",
    "inference = None\n",
    "# Assuming 'pdays' is a binary outcome variable with 1 for success and 0 for failure\n",
    "# You would need to replace 'success_count' and 'total_trials' with your actual data\n",
    "# success_count =  # Number of successes (e.g., number of '1's/ 'yes' in 'pdays')\n",
    "# total_trials = # Total number of trials (e.g., total number of observations)\n",
    "\n",
    "# Define the proportion you want to test against\n",
    "\n",
    "\n",
    "# Perform the binomial test\n",
    "\n",
    "\n",
    "# Determine significance based on the p-value\n",
    "\n",
    "\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Inference:\", inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the Functions\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "def binomial_test(success_count, total_trials, null_hypothesis_proportion, alpha=0.05):\n",
    "\n",
    "    # Code starts here\n",
    "    \"\"\"\n",
    "    Perform a binomial test to determine the significance of the observed proportion of successes.\n",
    "\n",
    "    Parameters:\n",
    "    - success_count (int): The number of successes.\n",
    "    - total_trials (int): The total number of trials or observations.\n",
    "    - null_hypothesis_proportion (float): The proportion specified in the null hypothesis.\n",
    "    - alpha (float): The significance level (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    - p_value (float): The p-value calculated from the binomial test.\n",
    "    - inference (str): The inference conclusion based on the p-value and significance level.\n",
    "    \"\"\"\n",
    "    # Perform the binomial test\n",
    "\n",
    "    # Determine significance based on the p-value\n",
    "\n",
    "\n",
    "        # Code ends here\n",
    "\n",
    "    return p_value, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b557c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "success_count = 120  # Number of successes (e.g., number of '1's/ 'yes' in 'pdays')\n",
    "total_trials = 250  # Total number of trials (e.g., total number of observations)\n",
    "null_hypothesis_proportion = 0.5  # Proportion specified in the null hypothesis\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "p_value, inference = binomial_test(success_count, total_trials, null_hypothesis_proportion, alpha)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Inference:\", inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb856a",
   "metadata": {},
   "source": [
    "#### T2.10\tUse the below function/ create a function of your own and drop null values from  ('job'), ('marital'), ('education'), ('housing') (weightage 2 marks) AE\n",
    "\n",
    " #### NOTE:\n",
    "- Design a Function `drop` to drop Null values from the Data Frame\n",
    "- Dropping null values from specific columns is a common data cleaning task to handle missing or incomplete data.\n",
    "- By removing rows with missing values in specific columns, we ensure that the data used for analysis or modeling is complete and reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops nulls\n",
    "import numpy as np\n",
    "\n",
    "def drop(column,df):\n",
    "    # Code starts here\n",
    "    \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "    # Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop('job',df)\n",
    "drop('marital',df)\n",
    "drop('education',df)\n",
    "drop('housing',df)\n",
    "\n",
    "# df.info()\n",
    "\n",
    "sns.countplot(data=df, x='y',palette='GnBu')\n",
    "plt.show()\n",
    "\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a233358",
   "metadata": {},
   "source": [
    "#### T2.11\tPerform data separation store all categorical variables in as ‘cat’ and All numeric variables in as ‘Numeric’ (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE:\n",
    "- Data separation involves segregating different types of variables in a dataset based on their data types or characteristics.\n",
    "- we aim to separate categorical variables, which represent qualitative attributes, from numeric variables, which represent quantitative attributes.\n",
    "- Categorical variables are qualitative variables that represent categories or groups.\n",
    "- Numeric variables are quantitative variables that represent numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae057357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all catogorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ee938",
   "metadata": {},
   "source": [
    "#### T2.12\tCreate countplot for all categorical variables (weightage 2 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fb8a7",
   "metadata": {},
   "source": [
    "#### T2.12\tCreate countplot for all categorical variables (weightage 2 marks) ME\n",
    "- Count plots are graphical representations that display the frequency or count of observations within different categories of a categorical variable.\n",
    "- They provide a visual summary of the distribution of categorical data, making it easier to understand the relative frequencies of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "\n",
    "# code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b435c7",
   "metadata": {},
   "source": [
    "#### T2.13\tChange datatype for ‘month’ and ‘day_of_week’ as ‘str’ (weightage 2 marks) ME\n",
    "\n",
    "- Numbers: to get number of numeric variables\n",
    "- Changing the data type of columns to 'str' converts the numerical or categorical values in the columns to string format.\n",
    "- This conversion is useful when treating these columns as categorical variables or when the values represent labels rather than numeric quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227206e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cd886",
   "metadata": {},
   "source": [
    "#### T2.14\tCreate histogram to know the Distribution of Attributes in the data frame df and check for normality (weightage 2 marks) ME\n",
    "\n",
    "- Histograms are graphical representations of the distribution of numerical data.\n",
    "- They provide a visual summary of the frequency or count of observations within different intervals, or \"bins,\" of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b439d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afabdc",
   "metadata": {},
   "source": [
    "#### T2.15\tGet Descriptive Statistics for all numeric variables (weightage 2 marks) ME\n",
    "\n",
    "- Hint: Using the code: np.log(df['campaign'] + 1) perform log transformation and create an histogram.\n",
    "\n",
    "- To get descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eaf311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c386cd",
   "metadata": {},
   "source": [
    "#### T2.16\tDrop variable duration from df (weightage 1 marks) ME\n",
    "\n",
    "- drop duration Coloumn\n",
    "- Dropping a variable can impact subsequent analysis, such as descriptive statistics, exploratory data analysis, or predictive modeling.\n",
    "- Ensure that dropping the \"duration\" variable does not compromise the integrity or quality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a7834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39638926",
   "metadata": {},
   "source": [
    "#### T2.17\tCreate Visualizations for: Correlations and Scatter plot and find with relevant statistical function Pearson's coefficient, if there is correlation or not, based on p values (weightage 2 marks) ME\n",
    "`Correlation Heatmap`:\n",
    "- Use seaborn's heatmap function to create a correlation heatmap.\n",
    "- The heatmap displays correlation coefficients between pairs of variables.\n",
    "\n",
    "`Scatter Plot`:\n",
    "- Use seaborn's scatterplot function to create scatter plots between pairs of variables.\n",
    "- Scatter plots visualize the relationship between two continuous variables.\n",
    "\n",
    "`Pearson's Correlation Coefficient`:\n",
    "- Calculate Pearson's correlation coefficient (also known as Pearson's r) to quantify the strength and direction of the linear relationship between two continuous variables.\n",
    "- Pearson's r ranges from -1 to 1, where:\n",
    "    - 1 indicates a perfect positive linear relationship,\n",
    "    - -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a12fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641a58c3",
   "metadata": {},
   "source": [
    "#### T2.18\tPerform Feature Engineering for all the features using get_dummies function except for target feature y  (weightage 2 marks) AE\n",
    "\n",
    "#### NOTE:\n",
    "- This function `dummy_function` should convert categorical variables into dummy variables using one-hot encoding, a common preprocessing technique in machine learning.\n",
    "- It must take a DataFrame (data) containing categorical variables as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285184f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = df.iloc[:,:-1]\n",
    "#print(df_features)\n",
    "\n",
    "def dummy_function(data):\n",
    "    # df_features = df.iloc[:,:-1]\n",
    "    df_features1 = None\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return df_features1\n",
    "\n",
    "#display(df_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=dummy_function(df) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bbdae",
   "metadata": {},
   "source": [
    "### Task 3: Build  model for predicting after splitting the dataset (weightage - 15 marks) \n",
    "\n",
    "#### NOTE:\n",
    "- Split the dataset into X and y, with test_size=0.33 and random_state=42\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f9956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b79a927",
   "metadata": {},
   "source": [
    "#### T3.1\tRandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=20) (weightage 5 marks) ME\n",
    "\n",
    "- Save the code for model versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c38d1",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using random forest.\n",
    "- Employ recursive feature elimination (RFE) for feature selection.\n",
    "- The function should take input features X and target variable y.\n",
    "- The function can iterate over a range of n_features, which specifies the number of features to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3deca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def select_features(X, y, test_size=0.2, n_features=[20]):\n",
    "    features = None\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "   # Code ends here\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = select_features(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca29d1",
   "metadata": {},
   "source": [
    "### Classification model\n",
    "#### T3.2\tCreate KNN model using the following parameters, KNeighborsClassifier(n_neighbors=10) Save the code for model versioning (weightage 5 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f703fe",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using KNeighbors.\n",
    "- The function should take input features (df_features), target feature (target_feature), and a list of features to consider (features).\n",
    "- The function can iterate over a range of n_features, which specifies the number of features to select.\n",
    "- The function must create a KNN classifier with the specified number of neighbors and fits it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63682edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_knn_model(df_features, target_feature, features):\n",
    "    knn = None\n",
    "\n",
    "    # Code starts here\n",
    "   \n",
    "    # Code ends here\n",
    "    \n",
    "    return knn  # Returning the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build the KNN model\n",
    "knn_model = build_knn_model(df_features, df['y'], select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302fb1f",
   "metadata": {},
   "source": [
    "#### T3.3\tCreate a Gradient boosting classifier model using the following parameters , GradientBoostingClassifier with options: n_estimators=100, random_state=42, max_depth=1. Save the code for model versioning (weightage 5 marks) ME\n",
    "\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19047b3e",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using Gradient Boosting.\n",
    "- define a function `build_gbrt_model` that takes input features X, target variable y, and some optional parameters like random_state, n_estimators, max_depth, and test_size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_gbrt_model(X, y, random_state=42, n_estimators=100, max_depth=1, test_size=0.2):\n",
    "    gbrt = None\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    return gbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt=build_gbrt_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e341d6",
   "metadata": {},
   "source": [
    "### Task 4: Evaluate the performance of the model using the right evaluation metrics.(weightage - 20 marks)                                                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5461f",
   "metadata": {},
   "source": [
    "#### T4.1\tEvaluate the above models by getting accuracy, Precision, Recall, F1 Score, Kappa Score\t(weightage - 4 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be66511",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbc6f2",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "-  Define a function which takes input as the test features (X_test), test labels (y_test), and the trained model (model).\n",
    "- Predict labels for the test set and then calculate evaluation metrics such as accuracy, precision, recall, and Cohen's kappa.\n",
    "**Range of results:** \n",
    "\n",
    "    -if accuracy +/-0.10  \n",
    "    -if precision +/-0.10  \n",
    "    -if recall +/-0.10  \n",
    "    -if kappa +/-0.10  \n",
    "\n",
    "    - all results are correct: 100%: 4 marks\n",
    "    - otherwise score: 3 marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae351abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def evaluate_model1(X_test, y_test, model):\n",
    "    accuracy,precision,recall,kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "   \n",
    "    return accuracy, precision, recall, kappa\n",
    "\n",
    "# Example usage:\n",
    "# accuracy, precision, recall, kappa = evaluate_model(X_test, y_test, your_model)  # Replace your_model with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_model1(X_test, y_test,select)[0]\n",
    "precision=evaluate_model1(X_test, y_test,select)[1]\n",
    "recall=evaluate_model1(X_test, y_test,select)[2]\n",
    "kappa=evaluate_model1(X_test, y_test,select)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f25ad1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b87055dd",
   "metadata": {},
   "source": [
    "### Knn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d2e86",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Evaluate a saved k-nearest neighbors (KNN) model using various classification metrics.\n",
    "- The Function should take a input the trained KNN model (knn_model), test features (X_test), and test labels (y_test).\n",
    "- Then it must predict labels for the test set using the provided KNN model and calculates evaluation metrics such as accuracy, precision, recall, and Cohen's kappa.\n",
    "\n",
    "\n",
    "\n",
    "**Range of results: \n",
    "\n",
    "-if accuracy +/-0.10  \n",
    "-if precision +/-0.10  \n",
    "-if recall +/-0.10  \n",
    "-if kappa +/-0.10  \n",
    "\n",
    "- all results are correct: 100%: 4 marks\n",
    "- otherwise score: 3 marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def evaluate_saved_knn_model(knn_model, X_test, y_test):\n",
    "    accuracy, precision, recall, kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "    return accuracy, precision, recall, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_saved_knn_model(knn_model, X_test, y_test)[0]\n",
    "precision=evaluate_saved_knn_model(knn_model, X_test, y_test)[1]\n",
    "recall=evaluate_saved_knn_model(knn_model, X_test, y_test)[2]\n",
    "kappa=evaluate_saved_knn_model(knn_model, X_test, y_test)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be31f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fb0b5",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b3cc7",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Define a Function that evaluates a Gradient Boosting Classifier model (gbrt) using various classification metrics.\n",
    "- The function must calculate metrics such as accuracy, precision, recall, and Cohen's kappa, based on the predictions made by the model on the test set.\n",
    "\n",
    "\n",
    "\n",
    "**Range of results: \n",
    "\n",
    "-if accuracy +/-0.10  \n",
    "-if precision +/-0.10  \n",
    "-if recall +/-0.10  \n",
    "-if kappa +/-0.10  \n",
    "\n",
    "- all results are correct: 100%: 4 marks\n",
    "- otherwise score: 3 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gbrt_model(gbrt, X_test, y_test):\n",
    "    accuracy, precision, recall, kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "    return accuracy, precision, recall, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_gbrt_model(gbrt, X_test, y_test)[0]\n",
    "precision=evaluate_gbrt_model(gbrt, X_test, y_test)[1]\n",
    "recall=evaluate_gbrt_model(gbrt, X_test, y_test)[2]\n",
    "kappa=evaluate_gbrt_model(gbrt, X_test, y_test)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc55704",
   "metadata": {},
   "source": [
    "#### T.4.2 Perform Hyperparameter tuning. Re build the model with best suitable modelling technique (weightage 5 marks) ME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46237ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "\n",
    "# Create the Gradient Boosting Classifier model\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "\n",
    "\n",
    "# Fit the Grid Search to find the best parameters\n",
    "\n",
    "# Get the best parameters and best score\n",
    "\n",
    "\n",
    "# Rebuild the model with the best parameters\n",
    "\n",
    "\n",
    "# Print the best parameters and best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeba79",
   "metadata": {},
   "source": [
    "#### T.4.3 Using Lime/SHAP libraries, explain the prediction of your classification model and give inferences.   (weightage 3 marks) ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "643ad8b5",
   "metadata": {},
   "source": [
    "#### T4.4 Implement unit test case and deploy the above models using Flask/ Stream lit\t(weightage - 8 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d82466",
   "metadata": {},
   "source": [
    "### Task 5: Summarize the findings of the analysis and draw conclusions with PPT / PDF. (weightage - 15 marks) (ME) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c126a",
   "metadata": {},
   "source": [
    "##### Classification Model Conclusions\n",
    "\n",
    "''' The Knn modelwith a test set score of 0.892 was obtained which is fairly good\n",
    "    but the gradient models are more effective\n",
    "    \n",
    "    By using the reduced dataset and the complete dataset to build the model, \n",
    "    we obtained the same results (test score of 0.90). \n",
    "    the reduced dataset, thought, run a bit faster (0.82 vs 1.06)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6d7d2",
   "metadata": {},
   "source": [
    "**Final Submission guidelines:**\n",
    "- Download the Jupyter notebook in the format of html. \n",
    "- Upload it in the lumen (UNext LMS)\n",
    "- Take a screenshot of T4.4 (Deployment) and upload it in the lumen (UNext LMS)\n",
    "- Summarized PPT/ PDF prepared in Task 5 to be uploaded in the lumen (UNext LMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb091539",
   "metadata": {},
   "source": [
    "-------------------------------------------------- **ASSESSMENT ENDS HERE** ---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
